	loss	val_loss	learning_rate	batch_size	epochs	sparsity	noise	seed
0	0.0786816583673	0.0770840535998	1.0	200	40	0.0	0.1	4815
1	0.0724374935661	0.0635842090156	1.0	200	40	0.0	0.1	4815
2	0.051961784763	0.0418926380489	1.0	200	40	0.0	0.1	4815
3	0.0385106089725	0.0367436998063	1.0	200	40	0.0	0.1	4815
4	0.036248339421	0.0360761741906	1.0	200	40	0.0	0.1	4815
5	0.0359080641196	0.0359256136272	1.0	200	40	0.0	0.1	4815
6	0.0357985903307	0.0358460329573	1.0	200	40	0.0	0.1	4815
7	0.0357331185409	0.0357871973819	1.0	200	40	0.0	0.1	4815
8	0.0356841059682	0.035740738147	1.0	200	40	0.0	0.1	4815
9	0.0356341058425	0.035691942749	1.0	200	40	0.0	0.1	4815
10	0.0355883762921	0.0356467599138	1.0	200	40	0.0	0.1	4815
11	0.0355420413107	0.0356023637916	1.0	200	40	0.0	0.1	4815
12	0.035497153112	0.0355546786512	1.0	200	40	0.0	0.1	4815
13	0.035451269267	0.0355075140186	1.0	200	40	0.0	0.1	4815
14	0.0354034116482	0.0354569604047	1.0	200	40	0.0	0.1	4815
15	0.0353530584649	0.0354083160198	1.0	200	40	0.0	0.1	4815
16	0.0352985089991	0.0353512698802	1.0	200	40	0.0	0.1	4815
17	0.035240939074	0.0352946477684	1.0	200	40	0.0	0.1	4815
18	0.0351826660984	0.0352274997598	1.0	200	40	0.0	0.1	4815
19	0.0351170901342	0.0351577114748	1.0	200	40	0.0	0.1	4815
20	0.0350460544728	0.035080239191	1.0	200	40	0.0	0.1	4815
21	0.0349669292447	0.0349962221419	1.0	200	40	0.0	0.1	4815
22	0.0348803318082	0.0349047920572	1.0	200	40	0.0	0.1	4815
23	0.0347907660553	0.0348051420304	1.0	200	40	0.0	0.1	4815
24	0.03468765144	0.0346948894428	1.0	200	40	0.0	0.1	4815
25	0.0345779912639	0.0345709431012	1.0	200	40	0.0	0.1	4815
26	0.0344539532369	0.0344405017195	1.0	200	40	0.0	0.1	4815
27	0.0343209253091	0.0342959148407	1.0	200	40	0.0	0.1	4815
28	0.0341748490551	0.034141117568	1.0	200	40	0.0	0.1	4815
29	0.0340197483226	0.0339713686967	1.0	200	40	0.0	0.1	4815
30	0.0338510955876	0.0337836370869	1.0	200	40	0.0	0.1	4815
31	0.0336668102474	0.033584308043	1.0	200	40	0.0	0.1	4815
32	0.0334705965209	0.0333726706756	1.0	200	40	0.0	0.1	4815
33	0.0332634762267	0.0331545526208	1.0	200	40	0.0	0.1	4815
34	0.0330481511902	0.0329224393769	1.0	200	40	0.0	0.1	4815
35	0.0328212559981	0.0326880087887	1.0	200	40	0.0	0.1	4815
36	0.0325921405929	0.0324473730137	1.0	200	40	0.0	0.1	4815
37	0.0323597641992	0.0322034340886	1.0	200	40	0.0	0.1	4815
38	0.0321225353768	0.0319613425442	1.0	200	40	0.0	0.1	4815
39	0.0318909938249	0.0317152906672	1.0	200	40	0.0	0.1	4815
