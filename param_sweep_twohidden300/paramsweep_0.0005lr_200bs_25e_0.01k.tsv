	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	3101.38720415	3010.27643067	0.0005	200	25	0.01	8612	2	300
1	2868.73476937	2929.31315026	0.0005	200	25	0.01	8612	2	300
2	2805.50251465	2857.78820171	0.0005	200	25	0.01	8612	2	300
3	2777.42139834	2807.84105792	0.0005	200	25	0.01	8612	2	300
4	2761.29437778	2774.1208216	0.0005	200	25	0.01	8612	2	300
5	2750.84853529	2761.14323399	0.0005	200	25	0.01	8612	2	300
6	2742.38850964	2748.6510745	0.0005	200	25	0.01	8612	2	300
7	2735.84060395	2737.5682058	0.0005	200	25	0.01	8612	2	300
8	2729.45973835	2730.41664442	0.0005	200	25	0.01	8612	2	300
9	2724.36945446	2724.83668813	0.0005	200	25	0.01	8612	2	300
10	2720.19260255	2721.32884949	0.0005	200	25	0.01	8612	2	300
11	2715.73801543	2716.75935857	0.0005	200	25	0.01	8612	2	300
12	2711.75165659	2710.88972779	0.0005	200	25	0.01	8612	2	300
13	2709.33565225	2706.84170071	0.0005	200	25	0.01	8612	2	300
14	2705.97458842	2703.71353482	0.0005	200	25	0.01	8612	2	300
15	2703.89329965	2704.22519989	0.0005	200	25	0.01	8612	2	300
16	2701.32491823	2700.47990018	0.0005	200	25	0.01	8612	2	300
17	2699.29576958	2698.16378755	0.0005	200	25	0.01	8612	2	300
18	2697.96061866	2698.46023169	0.0005	200	25	0.01	8612	2	300
19	2695.73326925	2694.95687814	0.0005	200	25	0.01	8612	2	300
20	2693.95635514	2693.57939659	0.0005	200	25	0.01	8612	2	300
21	2692.55903164	2691.59788078	0.0005	200	25	0.01	8612	2	300
22	2691.27560281	2689.21647571	0.0005	200	25	0.01	8612	2	300
23	2689.5737243	2689.44571769	0.0005	200	25	0.01	8612	2	300
24	2688.39559493	2687.33745649	0.0005	200	25	0.01	8612	2	300
