	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	2938.63482383	2950.23060412	0.002	200	25	1.0	7208	2	300
1	2773.70441947	2835.62778404	0.002	200	25	1.0	7208	2	300
2	2743.33837546	2805.4712717	0.002	200	25	1.0	7208	2	300
3	2726.3732593	2761.71135529	0.002	200	25	1.0	7208	2	300
4	2714.91940825	2741.76887538	0.002	200	25	1.0	7208	2	300
5	2705.95805787	2729.8619163	0.002	200	25	1.0	7208	2	300
6	2699.90968659	2709.726689	0.002	200	25	1.0	7208	2	300
7	2694.70137696	2700.60881856	0.002	200	25	1.0	7208	2	300
8	2691.46302871	2698.01366814	0.002	200	25	1.0	7208	2	300
9	2689.44656793	2695.48442121	0.002	200	25	1.0	7208	2	300
10	2685.91350813	2688.68034943	0.002	200	25	1.0	7208	2	300
11	2683.30976862	2683.26182051	0.002	200	25	1.0	7208	2	300
12	2681.37672564	2683.6119121	0.002	200	25	1.0	7208	2	300
13	2679.48362824	2680.98598689	0.002	200	25	1.0	7208	2	300
14	2678.04606093	2678.38319061	0.002	200	25	1.0	7208	2	300
15	2676.49582557	2676.70214564	0.002	200	25	1.0	7208	2	300
16	2675.09287327	2678.6357716	0.002	200	25	1.0	7208	2	300
17	2674.4721135	2675.84348532	0.002	200	25	1.0	7208	2	300
18	2672.91345294	2676.10074605	0.002	200	25	1.0	7208	2	300
19	2672.12211217	2673.89040747	0.002	200	25	1.0	7208	2	300
20	2670.76005788	2673.54176158	0.002	200	25	1.0	7208	2	300
21	2670.69791956	2671.67961001	0.002	200	25	1.0	7208	2	300
22	2668.98465836	2671.16140496	0.002	200	25	1.0	7208	2	300
23	2668.07197335	2669.1834131	0.002	200	25	1.0	7208	2	300
24	2667.65035937	2670.6856225	0.002	200	25	1.0	7208	2	300
