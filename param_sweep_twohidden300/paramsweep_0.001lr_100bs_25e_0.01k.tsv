	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	2924.61219964	2893.58451887	0.001	100	25	0.01	8180	2	300
1	2765.70057212	2778.66878846	0.001	100	25	0.01	8180	2	300
2	2737.15241443	2739.79703792	0.001	100	25	0.01	8180	2	300
3	2722.3579445	2718.08440404	0.001	100	25	0.01	8180	2	300
4	2711.8204426	2708.40678963	0.001	100	25	0.01	8180	2	300
5	2704.53884043	2698.39786659	0.001	100	25	0.01	8180	2	300
6	2699.0711412	2694.88217904	0.001	100	25	0.01	8180	2	300
7	2694.04565855	2689.99894175	0.001	100	25	0.01	8180	2	300
8	2690.6977945	2685.13407988	0.001	100	25	0.01	8180	2	300
9	2687.30557808	2681.76024317	0.001	100	25	0.01	8180	2	300
10	2684.47813835	2679.76611328	0.001	100	25	0.01	8180	2	300
11	2682.15805876	2680.38473342	0.001	100	25	0.01	8180	2	300
12	2680.19950553	2677.25697085	0.001	100	25	0.01	8180	2	300
13	2678.63425219	2675.28269244	0.001	100	25	0.01	8180	2	300
14	2677.28586987	2675.06001658	0.001	100	25	0.01	8180	2	300
15	2675.4482772	2671.83602199	0.001	100	25	0.01	8180	2	300
16	2674.40535781	2669.37923628	0.001	100	25	0.01	8180	2	300
17	2673.01754213	2669.73622309	0.001	100	25	0.01	8180	2	300
18	2672.34370106	2666.51261689	0.001	100	25	0.01	8180	2	300
19	2670.99832331	2667.42776799	0.001	100	25	0.01	8180	2	300
20	2670.43279509	2666.06324409	0.001	100	25	0.01	8180	2	300
21	2669.15954897	2665.40148296	0.001	100	25	0.01	8180	2	300
22	2668.82082516	2663.86566104	0.001	100	25	0.01	8180	2	300
23	2667.90521635	2667.52224714	0.001	100	25	0.01	8180	2	300
24	2667.6252818	2662.73626324	0.001	100	25	0.01	8180	2	300
