	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	2946.08758963	2990.07097117	0.002	200	50	0.1	9790	2	300
1	2775.29832882	2876.67992697	0.002	200	50	0.1	9790	2	300
2	2743.56900934	2804.83625913	0.002	200	50	0.1	9790	2	300
3	2726.34411086	2763.29737962	0.002	200	50	0.1	9790	2	300
4	2715.42125465	2735.90418297	0.002	200	50	0.1	9790	2	300
5	2706.39022433	2721.23225896	0.002	200	50	0.1	9790	2	300
6	2700.29554803	2711.20655977	0.002	200	50	0.1	9790	2	300
7	2697.19755349	2707.0130865	0.002	200	50	0.1	9790	2	300
8	2691.26808526	2698.78863724	0.002	200	50	0.1	9790	2	300
9	2688.50280872	2695.79927906	0.002	200	50	0.1	9790	2	300
10	2686.03748693	2696.30396722	0.002	200	50	0.1	9790	2	300
11	2683.92701985	2691.62028757	0.002	200	50	0.1	9790	2	300
12	2681.68128397	2689.01124821	0.002	200	50	0.1	9790	2	300
13	2679.75035862	2685.33655649	0.002	200	50	0.1	9790	2	300
14	2678.23686958	2683.95258584	0.002	200	50	0.1	9790	2	300
15	2677.66253852	2683.29007547	0.002	200	50	0.1	9790	2	300
16	2675.88542493	2680.95961737	0.002	200	50	0.1	9790	2	300
17	2674.51752687	2679.69735105	0.002	200	50	0.1	9790	2	300
18	2673.07845875	2680.29674103	0.002	200	50	0.1	9790	2	300
19	2671.94158371	2676.154042	0.002	200	50	0.1	9790	2	300
20	2671.02051072	2679.19358998	0.002	200	50	0.1	9790	2	300
21	2670.350261	2681.7489016	0.002	200	50	0.1	9790	2	300
22	2669.50163768	2678.12767248	0.002	200	50	0.1	9790	2	300
23	2668.40028719	2676.49092712	0.002	200	50	0.1	9790	2	300
24	2668.13347798	2674.93534101	0.002	200	50	0.1	9790	2	300
25	2668.27848091	2672.89510869	0.002	200	50	0.1	9790	2	300
26	2665.96599134	2672.51806034	0.002	200	50	0.1	9790	2	300
27	2666.15945975	2671.37104193	0.002	200	50	0.1	9790	2	300
28	2665.31758369	2671.23181642	0.002	200	50	0.1	9790	2	300
29	2665.31437635	2671.54469127	0.002	200	50	0.1	9790	2	300
30	2664.80255521	2670.41650811	0.002	200	50	0.1	9790	2	300
31	2664.01538146	2670.91927441	0.002	200	50	0.1	9790	2	300
32	2664.03329222	2670.49280369	0.002	200	50	0.1	9790	2	300
33	2664.48520092	2669.33328276	0.002	200	50	0.1	9790	2	300
34	2662.47922693	2668.62397069	0.002	200	50	0.1	9790	2	300
35	2663.21111662	2674.08887186	0.002	200	50	0.1	9790	2	300
36	2662.3178111	2668.21436247	0.002	200	50	0.1	9790	2	300
37	2662.29126617	2668.79503858	0.002	200	50	0.1	9790	2	300
38	2661.68987794	2669.79950546	0.002	200	50	0.1	9790	2	300
39	2661.08901171	2672.00329613	0.002	200	50	0.1	9790	2	300
40	2662.77336081	2671.15496628	0.002	200	50	0.1	9790	2	300
41	2660.7889684	2669.07716991	0.002	200	50	0.1	9790	2	300
42	2660.8976192	2667.35611154	0.002	200	50	0.1	9790	2	300
43	2660.21767939	2667.24157411	0.002	200	50	0.1	9790	2	300
44	2659.73052547	2668.01490472	0.002	200	50	0.1	9790	2	300
45	2659.41846505	2666.98719359	0.002	200	50	0.1	9790	2	300
46	2659.54865292	2664.62370834	0.002	200	50	0.1	9790	2	300
47	2659.03775377	2665.54352192	0.002	200	50	0.1	9790	2	300
48	2658.90718903	2665.95109625	0.002	200	50	0.1	9790	2	300
49	2658.79628946	2665.07354421	0.002	200	50	0.1	9790	2	300
