	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	3012.27934724	2972.78823345	0.001	200	25	0.01	6739	2	300
1	2809.85291828	2897.16258412	0.001	200	25	0.01	6739	2	300
2	2765.97644537	2820.36659932	0.001	200	25	0.01	6739	2	300
3	2745.97822529	2766.86432597	0.001	200	25	0.01	6739	2	300
4	2732.38929894	2750.87178089	0.001	200	25	0.01	6739	2	300
5	2722.93345102	2732.18381315	0.001	200	25	0.01	6739	2	300
6	2715.13763981	2721.53687644	0.001	200	25	0.01	6739	2	300
7	2709.2404386	2714.57946194	0.001	200	25	0.01	6739	2	300
8	2704.47440575	2708.52632751	0.001	200	25	0.01	6739	2	300
9	2701.07879313	2707.68383229	0.001	200	25	0.01	6739	2	300
10	2697.14803004	2698.61335547	0.001	200	25	0.01	6739	2	300
11	2694.60534545	2697.69439242	0.001	200	25	0.01	6739	2	300
12	2691.88596592	2693.34266467	0.001	200	25	0.01	6739	2	300
13	2689.95910431	2690.21988294	0.001	200	25	0.01	6739	2	300
14	2687.59741714	2687.89909103	0.001	200	25	0.01	6739	2	300
15	2686.16390595	2688.13086824	0.001	200	25	0.01	6739	2	300
16	2684.23571639	2684.88694795	0.001	200	25	0.01	6739	2	300
17	2682.64011304	2683.46729636	0.001	200	25	0.01	6739	2	300
18	2681.07819946	2684.81924351	0.001	200	25	0.01	6739	2	300
19	2679.84721912	2682.9197879	0.001	200	25	0.01	6739	2	300
20	2678.98506652	2680.48879521	0.001	200	25	0.01	6739	2	300
21	2677.44067663	2679.54165282	0.001	200	25	0.01	6739	2	300
22	2676.3374593	2677.32862869	0.001	200	25	0.01	6739	2	300
23	2675.03151357	2677.40692967	0.001	200	25	0.01	6739	2	300
24	2674.58439747	2678.72335086	0.001	200	25	0.01	6739	2	300
