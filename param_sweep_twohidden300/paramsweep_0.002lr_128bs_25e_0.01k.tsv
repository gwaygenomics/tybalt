	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	2895.8919189	2928.01984728	0.002	128	25	0.01	1212	2	300
1	2752.4698952	2777.25523572	0.002	128	25	0.01	1212	2	300
2	2724.90369857	2753.25026188	0.002	128	25	0.01	1212	2	300
3	2710.59769676	2714.89816955	0.002	128	25	0.01	1212	2	300
4	2702.1369825	2715.30556743	0.002	128	25	0.01	1212	2	300
5	2695.47722155	2696.81067058	0.002	128	25	0.01	1212	2	300
6	2690.47231192	2690.0368503	0.002	128	25	0.01	1212	2	300
7	2686.6191205	2686.98828452	0.002	128	25	0.01	1212	2	300
8	2683.82435764	2684.82161163	0.002	128	25	0.01	1212	2	300
9	2681.44015463	2679.45364549	0.002	128	25	0.01	1212	2	300
10	2678.90794233	2681.59796014	0.002	128	25	0.01	1212	2	300
11	2677.43059375	2677.87101393	0.002	128	25	0.01	1212	2	300
12	2675.07240846	2672.8610107	0.002	128	25	0.01	1212	2	300
13	2673.62424919	2672.11249141	0.002	128	25	0.01	1212	2	300
14	2672.11690892	2671.47510746	0.002	128	25	0.01	1212	2	300
15	2670.99306441	2669.47234209	0.002	128	25	0.01	1212	2	300
16	2669.77605968	2668.16108286	0.002	128	25	0.01	1212	2	300
17	2669.07174666	2670.00005322	0.002	128	25	0.01	1212	2	300
18	2668.21535312	2670.01139012	0.002	128	25	0.01	1212	2	300
19	2667.49615071	2666.928492	0.002	128	25	0.01	1212	2	300
20	2666.40659962	2667.13015076	0.002	128	25	0.01	1212	2	300
21	2666.36418654	2666.28915913	0.002	128	25	0.01	1212	2	300
22	2665.17404438	2665.64815975	0.002	128	25	0.01	1212	2	300
23	2664.5791463	2664.09576894	0.002	128	25	0.01	1212	2	300
24	2663.55229522	2664.07726047	0.002	128	25	0.01	1212	2	300
