	loss	val_loss	learning_rate	batch_size	epochs	kappa	seed	depth	first_layer
0	2915.57162367	2839.79395698	0.0005	50	25	0.1	2098	2	300
1	2771.28220734	2753.66190585	0.0005	50	25	0.1	2098	2	300
2	2743.66615153	2730.103433	0.0005	50	25	0.1	2098	2	300
3	2728.4838897	2714.78222236	0.0005	50	25	0.1	2098	2	300
4	2717.24157963	2703.64019414	0.0005	50	25	0.1	2098	2	300
5	2709.51185834	2700.57281179	0.0005	50	25	0.1	2098	2	300
6	2703.58490847	2692.79373245	0.0005	50	25	0.1	2098	2	300
7	2698.98703036	2689.92741461	0.0005	50	25	0.1	2098	2	300
8	2695.21801436	2684.8773093	0.0005	50	25	0.1	2098	2	300
9	2692.0189912	2682.86489827	0.0005	50	25	0.1	2098	2	300
10	2689.4361119	2680.72974053	0.0005	50	25	0.1	2098	2	300
11	2686.94133443	2678.30700707	0.0005	50	25	0.1	2098	2	300
12	2684.88552868	2676.2941101	0.0005	50	25	0.1	2098	2	300
13	2682.92337761	2676.37032912	0.0005	50	25	0.1	2098	2	300
14	2681.19830988	2673.45783136	0.0005	50	25	0.1	2098	2	300
15	2679.16604633	2673.17664531	0.0005	50	25	0.1	2098	2	300
16	2678.1538137	2672.42045637	0.0005	50	25	0.1	2098	2	300
17	2676.79346095	2668.75038325	0.0005	50	25	0.1	2098	2	300
18	2675.80762992	2668.87953411	0.0005	50	25	0.1	2098	2	300
19	2674.68455683	2668.66928141	0.0005	50	25	0.1	2098	2	300
20	2673.83465598	2666.02734048	0.0005	50	25	0.1	2098	2	300
21	2672.54946959	2667.94440736	0.0005	50	25	0.1	2098	2	300
22	2671.5717816	2664.38046399	0.0005	50	25	0.1	2098	2	300
23	2670.88501529	2664.88924325	0.0005	50	25	0.1	2098	2	300
24	2669.97514893	2663.2594678	0.0005	50	25	0.1	2098	2	300
